{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sledger9/TCS-iON-RIO-125/blob/main/GrammaticalErrorDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBCSTDyXQ6HJ",
        "outputId": "3f8ed66f-7b66-4981-bb0e-a371ae371ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "print(tf.__version__)\n",
        "import sys\n",
        "print(sys.version)\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lSbO3JxJL6j",
        "outputId": "fdedf02d-c5e6-4062-801c-0afa32366575"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RzyxC2xhSZRl"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Datasets/in_domain_train.csv\")\n",
        "data_dev = pd.read_csv(\"/content/drive/MyDrive/Datasets/in_domain_dev.csv\")\n",
        "data = data.values\n",
        "data_dev = data_dev.values\n",
        "x_train = data[:,1]\n",
        "y_train = data[:,2]\n",
        "\n",
        "x_dev = data_dev[:,1]\n",
        "y_dev = data_dev[:,2]\n",
        "\n",
        "y = np.concatenate((y_dev,y_train))\n",
        "x = np.concatenate((x_dev,x_train))\n",
        "import random\n",
        "random.shuffle(y)\n",
        "random.shuffle(x)  \n",
        "y_t_0 = y[1500:]\n",
        "y_d_0 = y[:1500]\n",
        "x_t_0 = x[1500:]\n",
        "x_d_0 = x[:1500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfro3TVLSlgj",
        "outputId": "cd1b20bf-7c67-4763-dcc1-1edaa2f0e44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\t307365\thttp://lang-8.com/18840/journals/84655\t21\tThey asked me to explain `` Ionic Bond `` in English .\n",
            " 65781\n"
          ]
        }
      ],
      "source": [
        "f = open('/content/drive/MyDrive/Datasets/entries.train')\n",
        "lines=f.readlines()\n",
        "sentences = []\n",
        "y = []\n",
        "line = 0\n",
        "cur = 0\n",
        "for x in lines:\n",
        "    cur = cur +1\n",
        "    if x=='\\n' : continue\n",
        "    else: line=line+1\n",
        "    if line>=60000: \n",
        "        print(x,cur)\n",
        "        break\n",
        "    sentences.append(x.split('\\t')[4])\n",
        "    if x.split('\\t')[0] == '0':\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D50Fr0_SoXu",
        "outputId": "a00a4c17-1fc7-4978-d592-469fde738375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59999 59999\n"
          ]
        }
      ],
      "source": [
        "print(len(y),len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfjX81wPSxa4",
        "outputId": "128386cc-e9ec-4155-9198-845db225f9ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29389 30610\n"
          ]
        }
      ],
      "source": [
        "zeros = 0\n",
        "ones = 0\n",
        "for l in y:\n",
        "    if l==0:\n",
        "        zeros = zeros+1\n",
        "    else:\n",
        "        ones = ones+1\n",
        "print(zeros,ones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XX7AWNeTpJ6",
        "outputId": "61406e4b-a5ae-4882-928d-1caf6e99fed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62351 6500 ['I really miss them .\\n' \"I 'm not sure how I spend more 3 weeks here .\"\n",
            " 'Oh my god !\\n'] ['Good luck on your new start !\\n'\n",
            " 'My teacher is going to move to change his job .\\n'\n",
            " 'He is a so nice guy and taught me English very kindly and was willing to accept my getting off the track .\\n']\n"
          ]
        }
      ],
      "source": [
        "y_t_1 = y[5000:]\n",
        "y_d_1 = y[:5000]\n",
        "x_t_1 = sentences[5000:]\n",
        "x_d_1 = sentences[:5000]\n",
        "\n",
        "y_t = np.concatenate((y_t_1,y_t_0.tolist()))\n",
        "y_d = np.concatenate((y_d_1,y_d_0.tolist()))\n",
        "sentences_t = np.concatenate((x_t_1,x_t_0))\n",
        "sentences_d = np.concatenate((x_d_1,x_d_0))\n",
        "\n",
        "print(len(y_t),len(y_d),sentences_t[:3],sentences_d[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GGXAxB5ZTvj4"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(sentences_t)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "sequences = tokenizer.texts_to_sequences(sentences_t)\n",
        "padded = pad_sequences(sequences,maxlen=max_length)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(sentences_d)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n",
        "\n",
        "y_train_np = np.array(y_t,np.float32)\n",
        "y_dev_np = np.array(y_d,np.float32)\n",
        "testing_padded_np = np.array(testing_padded,np.float32)\n",
        "padded_np = np.array(padded,np.float32)\n",
        "\n",
        "y_train_tf = tf.convert_to_tensor(y_train_np, np.float32)\n",
        "y_dev_tf = tf.convert_to_tensor(y_dev_np, np.float32)\n",
        "testing_padded_tf = tf.convert_to_tensor(testing_padded_np, np.float32)\n",
        "padded_tf = tf.convert_to_tensor(padded_np, np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EMs1tOVERWo",
        "outputId": "e50036bc-e2bd-4f27-96a2-2d13dc15fb06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.000e+00 0.000e+00 0.000e+00 ... 9.100e+01 6.920e+02 7.000e+01]\n",
            " [0.000e+00 0.000e+00 0.000e+00 ... 2.310e+02 6.310e+02 1.360e+02]\n",
            " [0.000e+00 0.000e+00 0.000e+00 ... 4.250e+02 7.000e+00 8.420e+02]\n",
            " ...\n",
            " [0.000e+00 0.000e+00 0.000e+00 ... 8.399e+03 2.161e+03 7.012e+03]\n",
            " [0.000e+00 0.000e+00 0.000e+00 ... 4.335e+03 5.230e+03 3.453e+03]\n",
            " [0.000e+00 0.000e+00 0.000e+00 ... 4.870e+02 4.800e+01 4.734e+03]]\n"
          ]
        }
      ],
      "source": [
        "print(padded_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wphSl8QlLswz",
        "outputId": "6c965bc9-587c-4cb5-c0c3-e12aabd5f1e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/drive/MyDrive/Datasets/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.array(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMhMV3mdLvbW",
        "outputId": "ab05d9c9-817a-4eba-ca84-00147541771e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104401\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for word,i in tokenizer.word_index.items():\n",
        "    cur = cur+1\n",
        "print(cur)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uEX75cRBMuqm"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJgKy37yMwsq",
        "outputId": "f14f1bae-211e-454a-c852-28864f9c76a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 120, 100)          3862100   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 64)               256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,904,927\n",
            "Trainable params: 42,699\n",
            "Non-trainable params: 3,862,228\n",
            "_________________________________________________________________\n",
            "None\n",
            "(6500,) (62351,) (62351, 120) (6500, 120)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False),\n",
        "    tf.keras.layers.LSTM(64,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy'])\n",
        "print(model.summary())\n",
        "print(y_dev_tf.shape,y_train_tf.shape,padded_tf.shape,testing_padded_tf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhlHalrzMzPm",
        "outputId": "6a145186-5cf2-4183-fa35-d791559f3434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6500, 120) (6500,) (62351, 120) (62351,)\n"
          ]
        }
      ],
      "source": [
        "print(testing_padded_tf.shape,y_dev_tf.shape,padded_tf.shape,y_train_tf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuOdPMjkM443",
        "outputId": "7016ee7c-a6a6-40e4-ffc7-3686267326ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1949/1949 [==============================] - 443s 224ms/step - loss: 0.6532 - accuracy: 0.6218 - val_loss: 0.6145 - val_accuracy: 0.6682\n",
            "Epoch 2/5\n",
            "1949/1949 [==============================] - 428s 220ms/step - loss: 0.6255 - accuracy: 0.6443 - val_loss: 0.6136 - val_accuracy: 0.6668\n",
            "Epoch 3/5\n",
            "1949/1949 [==============================] - 423s 217ms/step - loss: 0.6202 - accuracy: 0.6491 - val_loss: 0.6093 - val_accuracy: 0.6671\n",
            "Epoch 4/5\n",
            "1949/1949 [==============================] - 419s 215ms/step - loss: 0.6193 - accuracy: 0.6507 - val_loss: 0.6065 - val_accuracy: 0.6698\n",
            "Epoch 5/5\n",
            "1949/1949 [==============================] - 416s 213ms/step - loss: 0.6162 - accuracy: 0.6533 - val_loss: 0.6071 - val_accuracy: 0.6718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ddfcf9810>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "model.fit(padded_tf, y_train_tf, epochs=num_epochs, validation_data=(testing_padded_tf, y_dev_tf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWzkLaYsM8zC",
        "outputId": "cfd2a2fa-d36e-40ab-c875-77323279468a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I have reading the book\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "Grammatically \u001b[1m INCORRECT \u001b[0m with probability:  [[0.40681046]]\n",
            "[[0.59318954]]\n",
            "['I have reading the book']\n"
          ]
        }
      ],
      "source": [
        "custom = input(\"Sentence: \")\n",
        "custom_test_1 = np.array([custom])\n",
        "custom_1 = tokenizer.texts_to_sequences(custom_test_1)\n",
        "flag = 0\n",
        "for q in custom_1[0]:\n",
        "    if q!=1: \n",
        "        flag = 1\n",
        "        break\n",
        "if flag == 0: \n",
        "    print(\"All words out of vocabulary!\")\n",
        "custom_2 = pad_sequences(custom_1,maxlen=max_length)\n",
        "custom_np = np.array(custom_2,np.float32)\n",
        "custom_tf = tf.convert_to_tensor(custom_np,np.float32)\n",
        "prob = model.predict(custom_tf)\n",
        "if prob<0.65:\n",
        "    print(\"Grammatically \\033[1m INCORRECT \\033[0m with probability: \",1-prob)\n",
        "else:\n",
        "    print(\"Grammatically \\033[1m CORRECT \\033[0m with probability: \",prob)\n",
        "print(prob)\n",
        "print(custom_test_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIYErI5T4in0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}